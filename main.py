import os
import streamlit as st
import google.generativeai as genai
from langchain_community.vectorstores import FAISS
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

load_dotenv()


def get_conversational_chain():
    prompt_template = """ë‹¹ì‹ ì€ ì´ˆë“±í•™êµ ëŒë´„êµì‹¤, ë°©ê³¼í›„êµì‹¤, ëŠ˜ë´„êµì‹¤ ìš´ì˜ì— ê´€í•œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹´ë‹¹ êµì‚¬ë“¤ì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê°€ëŠ¥í•œ í•œ ìì„¸í•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë‹µë³€ì€ ì»¨í…ìŠ¤íŠ¸ ë‚´ì˜ ëª¨ë“  ê´€ë ¨ ì„¸ë¶€ ì •ë³´ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
ë§Œì•½ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì— ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ëª…í™•í•˜ê²Œ ì—†ìœ¼ë©´, 'ì œê³µëœ ì •ë³´ë¡œëŠ” ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³ ë§Œ ë§í•˜ê³ , ì¶”ì¸¡í•˜ê±°ë‚˜ ì˜ëª»ëœ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
ì»¨í…ìŠ¤íŠ¸:\n {context}\nì§ˆë¬¸: \n{input}\n\në‹µë³€:
"""

    model = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        temperature=0.2,
    )
    prompt = PromptTemplate(
        template=prompt_template,
        input_variables=["context", "input"],
    )
    stuff_documents_chain = create_stuff_documents_chain(model, prompt)
    return stuff_documents_chain


def clear_chat_history():
    st.session_state.messages = [
        {"role": "assistant", "content": "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}
    ]


def user_input(user_question):
    embeddings = GoogleGenerativeAIEmbeddings(
        model="models/embedding-001"
    )  # type: ignore

    # FAISS ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not os.path.exists("faiss_index"):
        st.error("ë²¡í„°DBê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return {"output_text": "ë²¡í„°DBê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}

    new_db = FAISS.load_local(
        "faiss_index", embeddings, allow_dangerous_deserialization=True
    )
    retriever = new_db.as_retriever()

    document_chain = get_conversational_chain()

    retrieval_chain = create_retrieval_chain(retriever, document_chain)

    response = retrieval_chain.invoke({"input": user_question})

    source_info = []
    for doc in response["context"]:
        if "source" in doc.metadata and "page" in doc.metadata:
            source_info.append(
                f"{doc.metadata['source']} (í˜ì´ì§€: {doc.metadata['page']})"
            )

    if source_info:
        unique_sources = sorted(list(set(source_info)))
        response_text = (
            response["answer"] + "\n\nì°¸ê³  ë¬¸ì„œ: " + "\n".join(unique_sources)
        )
    else:
        response_text = response["answer"]

    print(response_text)
    return {"output_text": response_text}


def main():
    st.set_page_config(page_title="ëŠ˜ë´„í•™êµ ìš´ì˜ ë„ìš°ë¯¸ ì±—ë´‡", page_icon="ğŸ’¬")

    st.title("ëŠ˜ë´„í•™êµ ìš´ì˜ ë„ìš°ë¯¸ ì±—ë´‡ ğŸ’¬")
    st.write("ëŠ˜ë´„í•™êµ ìš´ì˜ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!")

    st.button("ì±„íŒ… ê¸°ë¡ ì§€ìš°ê¸°", on_click=clear_chat_history)

    if "messages" not in st.session_state.keys():
        st.session_state.messages = [
            {
                "role": "assistant",
                "content": "ëŠ˜ë´„í•™êµ ìš´ì˜ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ì§ˆë¬¸í•´ì£¼ì„¸ìš”!",
            }
        ]

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])

    if prompt := st.chat_input("ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)

    if st.session_state.messages[-1]["role"] != "assistant":
        with st.chat_message("assistant"):
            with st.spinner("ìƒê° ì¤‘..."):
                response_dict = user_input(prompt)
                placeholder = st.empty()
                full_response = ""
                # user_input í•¨ìˆ˜ì—ì„œ ë°˜í™˜ëœ ë”•ì…”ë„ˆë¦¬ì˜ 'output_text' í‚¤ë¥¼ ì‚¬ìš©
                if response_dict and "output_text" in response_dict:
                    for item in response_dict["output_text"]:
                        full_response += item
                        placeholder.markdown(full_response)
                    placeholder.markdown(full_response)
                else:
                    full_response = "ì˜¤ë¥˜: ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    placeholder.markdown(full_response)
        if response_dict is not None:
            message = {"role": "assistant", "content": full_response}
            st.session_state.messages.append(message)


if __name__ == "__main__":
    main()
