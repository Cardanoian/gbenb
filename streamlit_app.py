# app.py

import os
import re
import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_openai import OpenAIEmbeddings
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv
from typing import List, TypedDict, Tuple

from langchain.chains.retrieval import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

load_dotenv()

llm_model = "gemini-2.5-flash"
embedding_model = "text-embedding-3-large"


class ContextDocument(TypedDict):
    source: str
    content: str


class ResponseDict(TypedDict):
    output_text: str
    source_documents: List[ContextDocument]


def get_conversational_chain():
    """ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ëŠ” ì²´ì¸ ìƒì„±"""
    prompt_template = """ë‹¹ì‹ ì€ ì´ˆë“±í•™êµ ëŒë´„êµì‹¤, ë°©ê³¼í›„êµì‹¤, ëŠ˜ë´„êµì‹¤ ìš´ì˜ì— ê´€í•œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì¤‘ìš”í•œ ì§€ì¹¨:**
1. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆëŠ”ì§€ ë¨¼ì € íŒë‹¨í•˜ì„¸ìš”.
2. ì»¨í…ìŠ¤íŠ¸ê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ì—†ë‹¤ë©´ "ì œê³µëœ ë¬¸ì„œì—ì„œ í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
3. ê´€ë ¨ ì •ë³´ê°€ ìˆë‹¤ë©´, ê·¸ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìì„¸í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
4. ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ê±°ë‚˜ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”.

ì œê³µëœ ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {input}

ë‹µë³€ ì§€ì¹¨:
- ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸ì˜ ê´€ë ¨ì„±ì„ ë¨¼ì € í‰ê°€í•˜ì„¸ìš”
- ê´€ë ¨ ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
- ë‹µë³€ì€ ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
- ê°€ë…ì„±ì„ ìœ„í•´ ì ì ˆí•œ ì¤„ë°”ê¿ˆê³¼ ë¬¸ë‹¨ì„ ì‚¬ìš©í•˜ì„¸ìš”

ë‹µë³€:"""

    model = ChatGoogleGenerativeAI(
        model=llm_model,
        temperature=0.3,  # ë” ì¼ê´€ëœ ë‹µë³€ì„ ìœ„í•´ ë‚®ì¶¤
    )

    prompt = PromptTemplate(
        template=prompt_template,
        input_variables=["context", "input"],
    )

    stuff_documents_chain = create_stuff_documents_chain(model, prompt)
    return stuff_documents_chain


def preprocess_question(question: str) -> str:
    """ì§ˆë¬¸ì„ ì „ì²˜ë¦¬í•˜ì—¬ ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì´ëŠ” í•¨ìˆ˜"""

    # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
    question = re.sub(r"\s+", " ", question).strip()

    # ì§ˆë¬¸ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if len(question) < 5:
        return question

    # ì¡´ëŒ“ë§ì„ í‰ì„œë¬¸ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
    question = re.sub(r"í•´\s*ì£¼ì„¸ìš”", "í•˜ëŠ” ë°©ë²•", question)
    question = re.sub(r"ì•Œë ¤\s*ì£¼ì„¸ìš”", "", question)
    question = re.sub(r"ê°€ë¥´ì³\s*ì£¼ì„¸ìš”", "", question)

    return question.strip()


def analyze_search_results(
    user_question: str, similar_docs: List[Tuple], threshold: float = 0.7
):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ëŠ” í•¨ìˆ˜"""

    if st.session_state.get("debug_mode", False):
        st.write(f"**ê²€ìƒ‰ ë¶„ì„ ê²°ê³¼**")
        st.write(f"ì§ˆë¬¸: {user_question}")
        st.write(f"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(similar_docs)}")

        relevant_docs = []
        for i, (doc, score) in enumerate(similar_docs):
            with st.expander(f"ë¬¸ì„œ {i+1} (ì ìˆ˜: {score:.3f})"):
                st.write(f"**ì¶œì²˜:** {doc.metadata.get('source', 'Unknown')}")
                st.write(f"**ë‚´ìš© ê¸¸ì´:** {len(doc.page_content)}")
                st.write(
                    f"**ê´€ë ¨ì„±:** {'ë†’ìŒ âœ…' if score >= threshold else 'ë‚®ìŒ âŒ'}"
                )
                st.write(f"**ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:**")
                st.text(
                    doc.page_content[:300] + "..."
                    if len(doc.page_content) > 300
                    else doc.page_content
                )

            if score >= threshold:
                relevant_docs.append((doc, score))

        st.write(f"ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œ ìˆ˜: {len(relevant_docs)}")
        return relevant_docs

    # ë””ë²„ê·¸ ëª¨ë“œê°€ ì•„ë‹ ë•ŒëŠ” ì½˜ì†”ì—ë§Œ ì¶œë ¥
    print(f"\n=== ì§ˆë¬¸: {user_question} ===")
    print(f"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(similar_docs)}")

    relevant_docs = []
    for i, (doc, score) in enumerate(similar_docs):
        print(f"\në¬¸ì„œ {i+1}:")
        print(f"  ì ìˆ˜: {score:.3f}")
        print(f"  ì¶œì²˜: {doc.metadata.get('source', 'Unknown')}")
        print(f"  ë‚´ìš© ê¸¸ì´: {len(doc.page_content)}")
        print(f"  ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc.page_content[:150]}...")

        if score >= threshold:
            relevant_docs.append((doc, score))
            print("  âœ… ê´€ë ¨ì„± ë†’ìŒ")
        else:
            print("  âŒ ê´€ë ¨ì„± ë‚®ìŒ")

    print(f"\nê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œ ìˆ˜: {len(relevant_docs)}")
    return relevant_docs


def check_vector_db_quality():
    """ë²¡í„° DBì˜ í’ˆì§ˆì„ ì²´í¬í•˜ëŠ” í•¨ìˆ˜"""

    if not os.path.exists("faiss_index"):
        st.error("ë²¡í„°DBê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    try:
        # embeddings = GoogleGenerativeAIEmbeddings(model=embedding_model)
        embeddings = OpenAIEmbeddings(model=embedding_model)
        db = FAISS.load_local(
            "faiss_index", embeddings, allow_dangerous_deserialization=True
        )

        # ë²¡í„° DB í†µê³„
        total_docs = db.index.ntotal
        st.success(f"ë²¡í„°DB ë¡œë“œ ì„±ê³µ!")
        st.write(f"**ì´ ë¬¸ì„œ ìˆ˜:** {total_docs}")

        # ìƒ˜í”Œ ë¬¸ì„œë“¤ í™•ì¸
        if total_docs > 0:
            sample_docs = db.similarity_search("", k=min(5, total_docs))
            st.write("**ìƒ˜í”Œ ë¬¸ì„œë“¤:**")
            for i, doc in enumerate(sample_docs):
                with st.expander(f"ìƒ˜í”Œ ë¬¸ì„œ {i+1}"):
                    st.write(f"**ì¶œì²˜:** {doc.metadata.get('source', 'Unknown')}")
                    st.write(f"**ê¸¸ì´:** {len(doc.page_content)}")
                    st.write(f"**ë‚´ìš©:**")
                    st.text(
                        doc.page_content[:200] + "..."
                        if len(doc.page_content) > 200
                        else doc.page_content
                    )

    except Exception as e:
        st.error(f"ë²¡í„°DB ì²´í¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def clear_chat_history():
    """ì±„íŒ… ê¸°ë¡ì„ ì§€ìš°ëŠ” í•¨ìˆ˜"""
    st.session_state.messages = [
        {"role": "assistant", "content": "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}
    ]


def user_input(user_question: str) -> ResponseDict:
    """ê°œì„ ëœ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ í•¨ìˆ˜"""
    # embeddings = GoogleGenerativeAIEmbeddings(model=embedding_model)
    embeddings = OpenAIEmbeddings(model=embedding_model)

    if not os.path.exists("faiss_index"):
        st.error("ë²¡í„°DBê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return {"output_text": "ë²¡í„°DBê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.", "source_documents": []}

    try:
        new_db = FAISS.load_local(
            "faiss_index", embeddings, allow_dangerous_deserialization=True
        )

        # ìœ ì‚¬ë„ ì„ê³„ê°’ ê°€ì ¸ì˜¤ê¸° (ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •)
        similarity_threshold = st.session_state.get(
            "similarity_threshold", 0.5
        )  # ê¸°ë³¸ê°’ì„ 0.5ë¡œ ë‚®ì¶¤

        # ì§ˆë¬¸ ì „ì²˜ë¦¬
        # user_question = preprocess_question(user_question)

        # ë‹¤ì¤‘ ê²€ìƒ‰ ì „ëµ ì ìš©
        search_results = []

        # 1. ì›ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ê²€ìƒ‰
        original_results = new_db.similarity_search_with_score(user_question, k=5)
        search_results.extend(original_results)

        # 2. ì „ì²˜ë¦¬ëœ ì§ˆë¬¸ìœ¼ë¡œ ê²€ìƒ‰
        if user_question != user_question:
            processed_results = new_db.similarity_search_with_score(user_question, k=5)
            search_results.extend(processed_results)

        # ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ë¡œ ì •ë ¬
        unique_results = {}
        for doc, score in search_results:
            doc_id = f"{doc.metadata.get('source', '')}_{hash(doc.page_content)}"
            if doc_id not in unique_results or unique_results[doc_id][1] > score:
                unique_results[doc_id] = (doc, score)

        # ì ìˆ˜ìˆœ ì •ë ¬
        similar_docs = sorted(unique_results.values(), key=lambda x: x[1])[:8]

        # ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„
        relevant_docs = analyze_search_results(
            user_question, similar_docs, similarity_threshold
        )

        # ì—¬ì „íˆ ê´€ë ¨ ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ì¡°ê¸° ë°˜í™˜
        if not relevant_docs:
            return {
                "output_text": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œì—ì„œ '{user_question}'ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\në‹¤ìŒì„ ì‹œë„í•´ë³´ì„¸ìš”:\n- ë” êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ ì‚¬ìš©\n- ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ ì§ˆë¬¸\n- ë””ë²„ê·¸ ëª¨ë“œì—ì„œ ê²€ìƒ‰ ê³¼ì • í™•ì¸",
                "source_documents": [],
            }

        # retriever ì„¤ì • ê°œì„ 
        retriever = new_db.as_retriever(
            search_type="similarity",
            search_kwargs={
                "k": 8,
            },
        )

        # RAG ì²´ì¸ ì‹¤í–‰
        document_chain = get_conversational_chain()
        retrieval_chain = create_retrieval_chain(retriever, document_chain)

        response = retrieval_chain.invoke({"input": user_question})

        # ì°¸ê³  ë¬¸ì„œ ì •ë³´ ìˆ˜ì§‘
        source_info: List[ContextDocument] = []
        for doc in response["context"]:
            if "source" in doc.metadata:
                source_info.append(
                    {
                        "source": doc.metadata["source"],
                        "content": doc.page_content,
                    }
                )

        response_text: str = response["answer"]

        return {"output_text": response_text, "source_documents": source_info}

    except Exception as e:
        st.error(f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {"output_text": f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", "source_documents": []}


def add_debug_sidebar():
    """ë””ë²„ê·¸ ëª¨ë“œ ì‚¬ì´ë“œë°” ì¶”ê°€"""
    with st.sidebar:
        st.header("ğŸ”§ ë””ë²„ê·¸ ëª¨ë“œ")

        # ë””ë²„ê·¸ ëª¨ë“œ í† ê¸€
        debug_mode = st.checkbox("ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”", key="debug_mode")

        if debug_mode:
            st.write("---")

            # ë²¡í„°DB í’ˆì§ˆ ì²´í¬ ë²„íŠ¼
            if st.button("ë²¡í„°DB í’ˆì§ˆ ì²´í¬"):
                check_vector_db_quality()

            # ìœ ì‚¬ë„ ì„ê³„ê°’ ì„¤ì •
            similarity_threshold = st.slider(
                "ìœ ì‚¬ë„ ì„ê³„ê°’",
                min_value=0.0,
                max_value=1.0,
                value=0.5,  # ê¸°ë³¸ê°’ì„ 0.5ë¡œ ë‚®ì¶¤
                step=0.1,
                key="similarity_threshold",
                help="ì´ ê°’ë³´ë‹¤ ë‚®ì€ ìœ ì‚¬ë„ì˜ ë¬¸ì„œëŠ” ê´€ë ¨ì„±ì´ ë‚®ë‹¤ê³  íŒë‹¨ë©ë‹ˆë‹¤.",
            )

            # ê²€ìƒ‰ ì„¤ì •
            st.write("**ê²€ìƒ‰ ì„¤ì •:**")
            st.write(f"- ìœ ì‚¬ë„ ì„ê³„ê°’: {similarity_threshold}")
            st.write(f"- ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜: 8ê°œ")
            st.write(f"- ëª¨ë¸ ì˜¨ë„: 0.3")
            st.write(f"- ë‹¤ì¤‘ ê²€ìƒ‰ ì „ëµ: âœ… í™œì„±í™”")

        return debug_mode


def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ í•¨ìˆ˜"""
    st.set_page_config(
        page_title="ëŠ˜ë´„í•™êµ ìš´ì˜ ë„ìš°ë¯¸ ì±—ë´‡", page_icon="nb_small.png", layout="wide"
    )

    # ë””ë²„ê·¸ ì‚¬ì´ë“œë°” ì¶”ê°€
    debug_mode = add_debug_sidebar()

    # ë©”ì¸ í—¤ë”
    col1, col2 = st.columns([1, 8])
    with col1:
        if os.path.exists("nb_small.png"):
            st.image("nb_small.png", use_container_width=True)
    with col2:
        st.markdown(
            """
            <div style="display:flex; align-items:center; height:54px;">
                <span style="font-size:2.2em; font-weight:bold; height:54px;">ëŠ˜ë´„í•™êµ ìš´ì˜ ë„ìš°ë¯¸ ì±—ë´‡</span>
            </div>
            """,
            unsafe_allow_html=True,
        )

    st.write("ë¬¸ì˜ì‚¬í•­ ë° ì˜¤ë¥˜ë³´ê³ : í¬í•­ì›ë™ì´ˆë“±í•™êµ êµì‚¬ ê¹€ì§€ì›")

    # ë””ë²„ê·¸ ëª¨ë“œ í‘œì‹œ
    if debug_mode:
        st.warning(
            "ğŸ”§ ë””ë²„ê·¸ ëª¨ë“œê°€ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê³¼ì •ì´ ìƒì„¸íˆ í‘œì‹œë©ë‹ˆë‹¤."
        )

    # ì±„íŒ… ê¸°ë¡ ì§€ìš°ê¸° ë²„íŠ¼
    if st.button("ì±„íŒ… ê¸°ë¡ ì§€ìš°ê¸°", key="clear_chat"):
        clear_chat_history()
        st.rerun()

    # ì±„íŒ… ë©”ì‹œì§€ ì´ˆê¸°í™”
    if "messages" not in st.session_state.keys():
        st.session_state.messages = [
            {
                "role": "assistant",
                "content": "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
            }
        ]

    # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)

        # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                # ì‘ë‹µ ìƒì„±
                response_dict = user_input(prompt)

                # ì‘ë‹µ í‘œì‹œ
                if response_dict and "output_text" in response_dict:
                    full_response = response_dict["output_text"]
                    st.markdown(full_response)

                    # ì°¸ê³  ë¬¸ì„œ í‘œì‹œ
                    if (
                        response_dict.get("source_documents")
                        and len(response_dict["source_documents"]) > 0
                    ):

                        st.markdown("---")
                        st.markdown("**ğŸ“š ì°¸ê³  ë¬¸ì„œ:**")

                        # ì†ŒìŠ¤ ë¬¸ì„œë¥¼ íŒŒì¼ë³„ë¡œ ê·¸ë£¹í™”
                        source_groups = {}
                        for doc in response_dict["source_documents"]:
                            source = doc.get("source", "Unknown")
                            if source not in source_groups:
                                source_groups[source] = []
                            source_groups[source].append(doc.get("content", ""))

                        # ê° íŒŒì¼ë³„ë¡œ expander ìƒì„±
                        for source, contents in source_groups.items():
                            with st.expander(f"ğŸ“„ {source} ({len(contents)}ê°œ ì„¹ì…˜)"):
                                for i, content in enumerate(contents, 1):
                                    st.write(f"**ì„¹ì…˜ {i}:**")
                                    st.write(content)
                                    if i < len(contents):
                                        st.write("---")

                    # ì‘ë‹µì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
                    st.session_state.messages.append(
                        {"role": "assistant", "content": full_response}
                    )

                else:
                    error_message = "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    st.error(error_message)
                    st.session_state.messages.append(
                        {"role": "assistant", "content": error_message}
                    )


if __name__ == "__main__":
    main()
